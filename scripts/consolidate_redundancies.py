#!/usr/bin/env python3
"""
Consolida conceitos redundantes na ontologia.
Estrat√©gia: fundir duplicatas mantendo o conceito mais desenvolvido
e transferir todas as rela√ß√µes para a vers√£o consolidada.
"""

import json
from pathlib import Path

# Redund√¢ncias identificadas: (manter, remover, motivo)
REDUNDANCIES = [
    {
        "keep": "madhyamaka",
        "remove": "madhyamika",
        "reason": "Madhyamika √© variante ortogr√°fica de madhyamaka - mesma escola budista"
    },
    {
        "keep": "intracao",
        "remove": "intra-a√ß√£o",
        "reason": "Conceito id√™ntico com dupla entrada - intracao tem descri√ß√£o mais completa"
    },
    {
        "keep": "recursao",
        "remove": "recurs√£o",
        "reason": "Recurs√£o gen√©rica subsumida por 'Recurs√£o Sem Fundamento' (epistemol√≥gica)"
    },
    {
        "keep": "hibrida√ß√£o",
        "remove": "hibridez",
        "reason": "Hibridez √© vers√£o abstrata/gen√©rica - hibrida√ß√£o tem contexto cultural espec√≠fico (Garc√≠a Canclini)"
    },
    {
        "keep": "escala",
        "remove": "escala",  # Ambos t√™m id "escala" - BUG!
        "reason": "DUPLICATA DE ID - dois conceitos com mesmo ID 'escala' (ontol√≥gica vs pol√≠tica)",
        "action": "RENOMEAR segundo para 'politica-escala'"
    },
    {
        "keep": "economia-solidaria",
        "remove": "economia solid√°ria",
        "reason": "DUPLICATA CR√çTICA - dois conceitos 'Economia Solid√°ria' (economia-solidaria mais desenvolvido com 7 conex√µes vs 4)"
    }
]

def load_json(filepath):
    """Carrega JSON com encoding UTF-8"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(filepath, data):
    """Salva JSON com indenta√ß√£o e UTF-8"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def consolidate_concepts(concepts_path, relations_path):
    """Consolida conceitos redundantes"""
    
    concepts = load_json(concepts_path)
    relations = load_json(relations_path)
    
    print(f"üìä Estado inicial: {len(concepts)} conceitos, {len(relations)} rela√ß√µes\n")
    
    # 1. Identificar e resolver duplicata de ID "escala"
    escala_concepts = [c for c in concepts if c['id'] == 'escala']
    if len(escala_concepts) == 2:
        print("‚ö†Ô∏è  DUPLICATA CR√çTICA: 2 conceitos com id='escala'")
        for i, c in enumerate(escala_concepts):
            print(f"   [{i}] layer={c['layer']}, name={c['name']}")
        
        # Renomear o pol√≠tico para 'politica-escala'
        for c in concepts:
            if c['id'] == 'escala' and c['layer'] == 'politica':
                old_id = c['id']
                c['id'] = 'politica-escala'
                print(f"   ‚úì Renomeado: 'escala' (politica) ‚Üí 'politica-escala'")
                
                # Atualizar rela√ß√µes
                for r in relations:
                    if r['from'] == old_id and r.get('from_layer') == 'politica':
                        r['from'] = 'politica-escala'
                    if r['to'] == old_id and r.get('to_layer') == 'politica':
                        r['to'] = 'politica-escala'
                
                # Atualizar conex√µes em outros conceitos
                for other in concepts:
                    if 'connections' in other and old_id in other['connections']:
                        # S√≥ atualizar se for refer√™ncia ao conceito pol√≠tico
                        # (heur√≠stica: se tem outras refs pol√≠ticas)
                        if other['layer'] in ['politica', 'pratica']:
                            idx = other['connections'].index(old_id)
                            other['connections'][idx] = 'politica-escala'
        print()
    
    # 2. Processar redund√¢ncias
    removed_count = 0
    updated_relations = 0
    
    for redundancy in REDUNDANCIES:
        keep_id = redundancy['keep']
        remove_id = redundancy['remove']
        reason = redundancy['reason']
        
        # Pular a duplicata de escala (j√° resolvida)
        if 'DUPLICATA DE ID' in reason:
            continue
        
        print(f"üîÑ Consolidando: {remove_id} ‚Üí {keep_id}")
        print(f"   Motivo: {reason}")
        
        # Verificar se ambos existem
        keep_concept = next((c for c in concepts if c['id'] == keep_id), None)
        remove_concept = next((c for c in concepts if c['id'] == remove_id), None)
        
        if not keep_concept:
            print(f"   ‚ö†Ô∏è  Conceito '{keep_id}' n√£o encontrado - pulando")
            continue
        if not remove_concept:
            print(f"   ‚ö†Ô∏è  Conceito '{remove_id}' n√£o encontrado - pulando")
            continue
        
        # Transferir conex√µes √∫nicas
        keep_connections = set(keep_concept.get('connections', []))
        remove_connections = set(remove_concept.get('connections', []))
        new_connections = remove_connections - keep_connections - {remove_id, keep_id}
        
        if new_connections:
            keep_concept['connections'].extend(sorted(new_connections))
            print(f"   + {len(new_connections)} conex√µes transferidas: {', '.join(new_connections)}")
        
        # Atualizar todas as rela√ß√µes que referenciam o conceito removido
        for relation in relations:
            if relation['from'] == remove_id:
                relation['from'] = keep_id
                updated_relations += 1
            if relation['to'] == remove_id:
                relation['to'] = keep_id
                updated_relations += 1
        
        # Atualizar refer√™ncias em connections de outros conceitos
        for concept in concepts:
            if concept['id'] != remove_id and 'connections' in concept:
                if remove_id in concept['connections']:
                    idx = concept['connections'].index(remove_id)
                    concept['connections'][idx] = keep_id
                    print(f"   ‚Ü™ Atualizada refer√™ncia em '{concept['id']}'")
        
        # Remover conceito redundante
        concepts = [c for c in concepts if c['id'] != remove_id]
        removed_count += 1
        print(f"   ‚úì Conceito '{remove_id}' removido\n")
    
    # 3. Remover duplicatas em connections (p√≥s-consolida√ß√£o)
    for concept in concepts:
        if 'connections' in concept:
            original_len = len(concept['connections'])
            concept['connections'] = sorted(list(set(concept['connections'])))
            if len(concept['connections']) < original_len:
                print(f"   üîß '{concept['id']}': {original_len - len(concept['connections'])} duplicatas removidas")
    
    # 4. Remover rela√ß√µes duplicadas
    seen_relations = set()
    unique_relations = []
    duplicates_removed = 0
    
    for rel in relations:
        key = (rel['from'], rel['to'], rel['name'])
        if key not in seen_relations:
            seen_relations.add(key)
            unique_relations.append(rel)
        else:
            duplicates_removed += 1
    
    if duplicates_removed > 0:
        print(f"\nüîß {duplicates_removed} rela√ß√µes duplicadas removidas")
    
    # Salvar
    save_json(concepts_path, concepts)
    save_json(relations_path, unique_relations)
    
    print(f"\n‚úÖ Consolida√ß√£o completa:")
    print(f"   Conceitos: {len(load_json(concepts_path))} ({len(concepts)} ‚Üí {len(concepts) - removed_count} = -{removed_count})")
    print(f"   Rela√ß√µes: {len(unique_relations)} (atualizada {updated_relations} refer√™ncias, -{duplicates_removed} duplicatas)")
    
    return {
        'removed_concepts': removed_count,
        'updated_relations': updated_relations,
        'removed_duplicates': duplicates_removed
    }

if __name__ == '__main__':
    base_path = Path(__file__).parent.parent / 'assets'
    concepts_path = base_path / 'concepts.json'
    relations_path = base_path / 'relations.json'
    
    print("=" * 60)
    print("CONSOLIDA√á√ÉO DE REDUND√ÇNCIAS CONCEITUAIS")
    print("=" * 60 + "\n")
    
    result = consolidate_concepts(concepts_path, relations_path)
    
    print("\n" + "=" * 60)
